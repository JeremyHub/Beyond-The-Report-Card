---
title: "Beyond the Report Card: Investigating the Factors that Define Educational Achievement"
author: "Thu Dang, Nathaniel Reimer, Jeremy Hubinger"
date: "`r Sys.Date()`"
output: html_document
---
```{r}
library(tidyverse)
library(MetBrewer)
library(sf)
library(rnaturalearth)
library(ggplot2)
```

```{r load wide data, include=FALSE}
load("wide_merged_data.Rdata")
```

# Intermediate Narrative

## Description & motivation of research questions

Initially, our focus was on the correlation between affordable housing and educational achievement. However, during the process of selecting appropriate educational proxies, we found ourselves delving into the factors behind the measurements of these proxies. As a result, we decided to seek the guidance of Leslie, who specializes in public policies in education. We hope to gain a better understanding of the educational proxies currently in use, and to investigate whether there are additional factors that impact educational outcomes and potentially render the current proxies interchangeable or distinct from other measures.


## Dataset description

The data set we have includes a range of school-related variables such as location details, funding, and aggregated scores in various subjects. Specifically, the score variables cover the general grade-cohort-standardized achievement score, as well as scores in reading, science, and physical education. 

We aggregate our dataset from 5 different datasets. We use data from The California Department of Education, Georgetown University, and the Educational Opportunity Project at Stanford University.

**Science Testing Data**
Our science test data is from the California Department of Education, specifically, from the 2021-2022 school year. It is from the California Science Test, in which there are three different categories. Life sciences, Physical sciences, and Earth and Space sciences.

**English Testing Data**
The data we have for English Language Arts / Literature is also from the California Department of Education, specifically from 2022. It tells us for each student group within each school their level of proficiency.

**Pys Ed Data**
Our PE data comes from the California Department Education from the 2018-2019 school year. It has 7 different types of exercises and each school's grade's proficiency on each type of exercise.

**School Funding Data**
Our school funding data is aggregated 2019-2020 data from different federal and state sources. It is compiled into the dataset we are using by Georgetown University researchers. It has information about funding going to a school from the state, local, and federal governments, as well as metadata about the school such as enrollment, as well as data about the income levels of the students at the school.


**Educational Opportunity Project at Stanford University**

Add description

You should have a description of the datasets you use. At this point, this can be just a few example records and description of their purpose.

**School Details**

This contains metadata on 10629 California Schools. Including both the nationally used NCES id and the California CDS code. We use this to join our data from our different sources. This dataset also contains the longitude and latitude of the schools which has been very useful for EDA so far.   


## Ethical issues (who may be harmed and who may benefit)

To ensure privacy concerns are addressed, we take measures to aggregate the data at the school level. However, we recognize that there may be potential issues with bias in the data collection process and data accuracy as a result.

Regarding potential bias, the data is taken from various sources, and it is possible that each school may have different processes for collecting the data. With the exception of the Educational Opportunity Project at Stanford University, we do not have information on the number of students for whom the data is collected, nor the demographic makeup of those students. As a result, we acknowledge that there may be inherent biases in the data that we cannot control due to a lack of information.

Regarding data accuracy, as we do not have detailed documentation for all of the datasets, it is challenging to ascertain their accuracy. However, we have confidence in the reliability of the government and highly-credited sources from which the data originates. Given this, we consider these datasets to be our most reliable option at present.

Taken out of context, our analyses and graphics have the potential to negatively impact educational policy. Particularly since we will be looking at demographics and funding data. We need to be careful and deliberate in our analysis in order to minimize harm.

## Analyses with a short description of results

*Thu's results*


*Jeremy's results*
I analyzed only the schools for which we have all data available. (as in the intersection of our datasets.) Amoung these schools, across all metrics, an increase in per-pupil government (both state and federal) spending correlated with a decrease in performance. Initial reactions is that these results are becuase of the increase in per-pupil spending when a high percentage of students are english learners, in the foster care system, or on free/reduced lunch.

```{r}
min_max_norm <- function(x) {
    (x - min(x, na.rm=TRUE)) / (max(x, na.rm=TRUE) - min(x, na.rm=TRUE))
}

# model metrics by per pupil funding
grouped_merged_table <- merged_table %>%
  filter(flag_nerds == 'false' || is.na(flag_nerds)) %>%
  filter(flag_f33 != '1' || is.na(flag_f33)) %>%
  mutate(pp_total_raw = as.numeric(pp_total_raw))%>%
  filter(pp_total_raw < 100000) %>% #filters 1 school out
  # mutate to then as.numeric
  mutate(
      science_data_Earth.and.Space.Sciences.Domain.Percent.Above.Standard = as.numeric(science_data_Earth.and.Space.Sciences.Domain.Percent.Above.Standard),
      science_data_Physical.Sciences.Domain.Percent.Above.Standard = as.numeric(science_data_Physical.Sciences.Domain.Percent.Above.Standard),
      science_data_Life.Sciences.Domain.Percent.Above.Standard = as.numeric(science_data_Life.Sciences.Domain.Percent.Above.Standard),
      ela_data_currstatus = as.numeric(ela_data_currstatus),
      gcs_mn_avg_ol = as.numeric(gcs_mn_avg_ol)
  ) %>%
  mutate(ela_data_currstatus = ela_data_currstatus * ela_data_currdenom) %>%
  group_by(CDSCode, pp_total_raw, Latitude, Longitude) %>%
  summarise(
    science_data_Earth.and.Space.Sciences.Domain.Percent.Above.Standard = mean(science_data_Earth.and.Space.Sciences.Domain.Percent.Above.Standard, na.rm = TRUE),
    science_data_Physical.Sciences.Domain.Percent.Above.Standard = mean(science_data_Physical.Sciences.Domain.Percent.Above.Standard, na.rm = TRUE),
    science_data_Life.Sciences.Domain.Percent.Above.Standard = mean(science_data_Life.Sciences.Domain.Percent.Above.Standard, na.rm = TRUE),
    ela_data_currstatus = mean(ela_data_currstatus, na.rm = TRUE),
    gcs_mn_avg_ol = mean(gcs_mn_avg_ol, na.rm = TRUE),
  ) %>%
  ungroup()

graph_ready <- grouped_merged_table %>%
  na.omit() %>% #only looking at the same schools. this line is doing a lot though
  filter(pp_total_raw < 20000) %>% # removes 2 schools
  # normalize the metrics
    mutate(
        science_data_Earth.and.Space.Sciences.Domain.Percent.Above.Standard = min_max_norm(science_data_Earth.and.Space.Sciences.Domain.Percent.Above.Standard),
        science_data_Physical.Sciences.Domain.Percent.Above.Standard = min_max_norm(science_data_Physical.Sciences.Domain.Percent.Above.Standard),
        science_data_Life.Sciences.Domain.Percent.Above.Standard = min_max_norm(science_data_Life.Sciences.Domain.Percent.Above.Standard),
        ela_data_currstatus = min_max_norm(ela_data_currstatus),
        gcs_mn_avg_ol = min_max_norm(gcs_mn_avg_ol)
    ) %>%
  group_by(CDSCode) %>%
  pivot_longer(cols=c(science_data_Earth.and.Space.Sciences.Domain.Percent.Above.Standard,science_data_Physical.Sciences.Domain.Percent.Above.Standard,science_data_Life.Sciences.Domain.Percent.Above.Standard,ela_data_currstatus,gcs_mn_avg_ol))
fl <- c("English Language Arts", "Grade Cohort Standardized", "Earth + Space", "Life Sciences", "Physical Sciences")
names(fl) <- c("ela_data_currstatus", "gcs_mn_avg_ol", "science_data_Earth.and.Space.Sciences.Domain.Percent.Above.Standard", "science_data_Life.Sciences.Domain.Percent.Above.Standard", "science_data_Physical.Sciences.Domain.Percent.Above.Standard")
graph_ready %>%
  ggplot(aes(color = name, y = pp_total_raw, x = value)) +
  geom_point(alpha=0.3)+
  facet_wrap(~name, labeller=labeller(name=fl))+
  geom_smooth()+
  labs(x = "Per Pupil Funding", y = "Normalized Metric", title = "Metric Performance by Total Per-Pupil Funding") +
  theme_bw() +
  theme(
    legend.title = element_blank(),
    legend.text = element_text(size = 8),
    legend.position = "none"
  )
```


*Nathaniel's results*
```{r message=FALSE, warning=FALSE, include=FALSE}
theme_nr <- function(){
  theme_minimal() %+replace%
  theme(
    
    axis.ticks = element_line(),
    
    plot.title = element_text(
      size = 14,
      hjust = 0
    ),
    plot.subtitle = element_text(
      size = 10,
      hjust = 0
    ),
    plot.caption = element_text(
      size = 8,
      hjust = 1
    ),
    axis.title = element_text(
      size = 10
    ),
    axis.text = element_text(
      size = 8
    )
  )
}
```

```{r funding models}
fundingmod<-wide_merged_data %>% 
  filter(!is.na(pp_total_raw)&!is.na(perfrl)) %>% 
  lm(formula = as.numeric(pp_total_raw) ~ as.numeric(perfrl) + 
       as.numeric(lep_flag) + 
       as.numeric(perfrl)*as.numeric(lep_flag)) %>%
  summary()

lunchfundingmod<-wide_merged_data %>% 
  filter(!is.na(pp_total_raw)&!is.na(perfrl)) %>% 
  lm(formula = as.numeric(pp_total_raw) ~ as.numeric(perfrl)) %>%
  summary()

fundingmod$coefficients
lunchfundingmod$coefficients
```

```{r, fig.height=6,fig.width=8}
fl<-c("Adjusted Spending","Raw Spending")

wide_merged_data %>%
  mutate(pp_total_raw_frl_adjusted = as.numeric(pp_total_raw) - as.numeric(perfrl)*lunchfundingmod$coefficients[2],
  pp_total_raw = as.numeric(pp_total_raw)) %>%
  pivot_longer(cols = c(pp_total_raw_frl_adjusted,pp_total_raw)) %>%
  ggplot(aes(x=value, y=gcs_mn_avg_ol-gradecenter, color = name)) + 
    geom_point(alpha = .1)+
    geom_smooth() +
    geom_hline(yintercept = 0, alpha=.5) + 
    scale_x_continuous(limits = c(8000,18000)) +
    scale_y_continuous(limits = c(-4, 4)) +
    scale_color_discrete(labels = c("Raw Spending", "Adjusted Spending")) + 
    labs(x = "Per Student Funding", y = "Grade Cohort Score", color="") + 
    theme_nr() + 
    theme(legend.position = c(.8,.81))
```



Brianna's note: I should be able to download the datasets you share and run your single RMD to reproduce it. Include any datasets, analysis, visualizations, etc. you have should be included in the RMD.

For each result (visualization, table, or data point), you should have a sentence or two describing the result.



## Project plan




## Summary of contributions
