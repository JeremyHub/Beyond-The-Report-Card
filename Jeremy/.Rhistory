library(keras)
# install_keras() # Uncomment this line and run it once to install the newest version of keras on your computer, then comment out this line again
library(dplyr)
# Step 1:
all_data <- read.csv('https://raw.githubusercontent.com/JeremyHub/STAT-456-Final/main/Jeremy/train.csv')
# Step 2:
train <- all_data[,sapply(all_data, is.numeric)] %>%
sapply(function(x) (x - min(x)) / (max(x) - min(x))) %>% # applies the function to perform min-max scaling
as.data.frame() %>%
select(-LotFrontage,-MasVnrArea,-GarageYrBlt) %>% # filters out all non-numeric columns as the model doesn't know how to handle strings (if you wanted it to handle categorical strings, you could map each string to a number and let the model figure out that it is categorical)
na.omit()
test <- train[0:500,] # the first 500 rows belongs to the test set
train <- train[500:nrow(train),] # the rest of the dataset belongs to the training set
x_train <- train %>%
select(-SalePrice,-Id) # keeps all columns except SalePrice and Id since they're not predictors
y_train <- train %>%
select(SalePrice) # assigns SalePrice to y as an outcome variable
x_test <- test %>%
select(-SalePrice,-Id)
y_test <- test %>%
select(SalePrice)
# reshape
x_train <- x_train %>%
unlist() %>%
array(dim = c(nrow(x_train),33))
x_test <- x_test %>%
unlist() %>%
array(dim = c(nrow(x_test),33))
y_train <- y_train %>%
unlist() %>%
array(dim=c(nrow(y_train),1))
y_test <- y_test %>%
unlist() %>%
array(dim=c(nrow(y_test),1))
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu', input_shape = c(33)) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 64, activation = 'relu') %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 1, activation = 'linear')
summary(model)
model %>% compile(
loss = 'mean_squared_error',
optimizer = 'adam',
metrics = c('mae')
)
history <- model %>% fit(
x_train, y_train,
epochs = 300, batch_size = 256,
validation_split = 0.2
)
plot(history)
results <- model %>% evaluate(x_test, y_test)
results[2] * (max(all_data$SalePrice) - min(all_data$SalePrice)) + min(all_data$SalePrice)
256*33
8704/256
32896/128
model %>% compile(
loss = 'mean_squared_error',
optimizer = 'adam',
metrics = c('mae')
)
