```{r}
#library(keras)
library(dplyr)
library(tidyr)
library(neuralnet)
library(tidyverse)
```

# Read in the data

- Step 1: Read in the data.

- Step 2: Use a scaling method to standardize the numeric variables. Different numeric variables measure different things, hence they have different scalings. In order to maximize the neural network model, we have to standardize the numerical variables to the same scale. There are different standardization methods we can use, i.e. standard scaling, min-max scaling. We'll be using min-max scaling for this dataset.

- Step 3: Split the dataset into training and testing set. The test data that we have reserved will only be used at the very end to evaluate the model.

```{r}
# Step 1:
all_data <- read.csv('https://raw.githubusercontent.com/JeremyHub/STAT-456-Final/main/Jeremy/train.csv') # characteristics of homes sold in an Iowa town between 2006 and 2010. Compiled specifically for use in data science education.

# Step 2: 
train <- all_data[,sapply(all_data, is.numeric)] %>%
  sapply(function(x) (x - min(x)) / (max(x) - min(x))) %>% # applies the function to perform min-max scaling
  as.data.frame() %>%
  select(-LotFrontage,-MasVnrArea,-GarageYrBlt) %>% # filters out all non-numeric columns as the model doesn't know how to handle strings (if you wanted it to handle categorical strings, you could map each string to a number and let the model figure out that it is categorical)
  na.omit()

test <- train[0:500,] # the first 500 rows belongs to the test set
train <- train[500:nrow(train),] # the rest of the dataset belongs to the training set
```

# Build a neural network on the data!

+ `model` is what variables the nueralnet should take into account and what it is trying to predict. If you have done any modeling in 155 or 253, this kind of thing will look very familar. Feel free to change the model and see what happens.

+ `data` is the data to use (we will use the data we reserved for training)

+ `hidden` is the number of hidden nodes that the network will have. Increasing these numbers and / or adding more layers (numbers) to the list will increase training time but might improve model performance.

+ `linear.output` tells the model if the thing it is trying to predict is categorical or numerical in nature. We are trying to predict house price, which is numerical, so we will set it to TRUE.

```{r}
model = neuralnet(SalePrice ~ LotArea + OverallQual,
data=train,
hidden=c(4,2),
linear.output = TRUE
)
```

# Check the shape of our model

We can see a our model, the shape, and the parameters belonging to each of the layer in our neural network model. 

The input nodes' values are governed by what the input is for any particular row in the dataset. Then that value is multiplied by the values on the lines leading to the next nodes, and so on and so on until it gets to the end.

 Read here for more detailed explanation on how to calculate the number of trainable parameters and a relevant exercise: https://aldozaimi.wordpress.com/2020/02/13/determine-the-number-of-trainable-parameters-in-a-neural-network/#:~:text=There%20is%20a%20simple%20rule,the%20number%20of%20output%20units.

```{r}
plot(model,rep = "best")
```

# Look at Results

Overall, the standardized error is ~0.002 (your results may vary because there is a lot of randomness in this process) for our model. 

```{r}
pred <- predict(model, test)

diff <- cbind(pred, test) %>%
  mutate(diff = pred-SalePrice) %>%
  summarize(mean_diff=mean(diff))

diff
```

# Making Sense of the Result

 In order to make sense of this number, we have to convert it to the scale of our outcome variable, which is house price. Since we use `min-max scaling` for this dataset, this line below helps us convert the error to the same scale with the outcome variable.
 
```{r}

diff$mean * (max(all_data$SalePrice) - min(all_data$SalePrice)) + min(all_data$SalePrice)
```

Since the error is ~36k (again, your results may vary), this means that the average absolute difference between the predicted house prices and the actual house prices in the test dataset is approximately $36K.

## Exercise

Now it's your turn to try predicting the make of a car using Neural Networks!

```{r}
cars_data <- read.csv("https://raw.githubusercontent.com/JeremyHub/STAT-456-Final/main/Jeremy/car%20details%20v4.csv") # data on used car characteristics from Kaggle. Creator used web scraping to compile data. 

# some data cleaning done for you, this does not need adjustment
cars_data_clean <- cars_data %>%
  separate(Max.Power, c("bhp_power", "rpm_power"), " @ ") %>%
  separate(Max.Torque, c("nm_torque", "rpm_torque"), " @ ") %>%
  mutate_at(c("bhp_power","Engine","rpm_power","nm_torque","rpm_torque"), ~ as.numeric(gsub("(\\s)*[a-zA-Z]*", "",.))) %>%
  select(-Fuel.Type,-Transmission,-Location,-Color,-Drivetrain,-Model,-Seller.Type,-Owner) %>%
  na.omit() %>%
  mutate(Make = as.factor(Make))
head(cars_data_clean)
```

# Seperate Training and Testing

```{r}
test <- cars_data_clean[???
train <- cars_data_clean[???
```

# Train Your Model

+ `act.fct` allows us to determine whether a neuron should be activated or not (and how much weight to give that activation). Some common activation functions are ReLU, sigmoid, and tanh. If you want to read more on ReLU activation function, read here: https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/#:~:text=The%20rectified%20linear%20activation%20function,otherwise%2C%20it%20will%20output%20zero.

```{r}
model = neuralnet(Year ~ ???,
data=train,
hidden=c(???),
linear.output = TRUE,
act.fct="tanh"
)
```

# Look at the Model

```{r}
plot(model,rep = "best")
```

# How Good is it?

```{r}
predict(model, test) %>%
  cbind(pred, test) %>%
  mutate(diff = pred-Year) %>%
  summarize(mean=mean(diff))
```

# Play Around with the Above and See if You Can Improve It!
