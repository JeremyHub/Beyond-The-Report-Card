[
  {
    "objectID": "school_insights.html",
    "href": "school_insights.html",
    "title": "Beyond the Report Card: What are the insights at the school level that we can observe?",
    "section": "",
    "text": "School-level academic achievement across California\nLet’s now take a closer look at the statistics on the individual school level. To create this map, we find the GCS score for each school and divide the schools into 5 categories, then we place a marker at the approximate location based on available latitude and longitude data. Note that the range of GCS scores is much wider now since we are looking at individual schools rather than the county average.\n\n\n\n\n\n\n Schools closer to urban areas appear to have higher achievement than schools in rural areas. Zooming in on just the San Francisco Bay we see that there is a tremendous amount of variation in achievement: schools in San Jose are years behind while a swath of schools in Palo Alto, Mountain View, and Cupertino boast testing achievement more than three years ahead. On the east side of the bay in Oakland, schools just blocks apart are separated by multiple years in achievement. Further afield, Los Angeles and Sacramento have areas of very low achievement then areas of higher achievement further out, almost resembling a bullseye. How do we account for this variation?\n\n\nDoes funding impact school-level academic achievement?\nAdvocacy groups have long debated the influence of funding on academic achievement. Conservative groups like The Heritage Foundation note that funding, in real terms, has increased significantly since the 70s but achievement has stayed flat. They argue that more funding will do little to improve outcomes (Lips, Watkins, and Fleming 2008). On the other hand, an assortment of studies find that funding does have a measurable impact on achievement, but how the money is spent important (Burnette 2019).\nWe map California school per-pupil funding data in four spending categories. There are schools with funding well in excess of $20,000 per student, but most are accurately represented by these categories.\n\n\n\n\n\n\n There are a striking number of schools with no funding data. Nevertheless, the types of areas that are excluded don’t appear to follow a clear trend.\nAmong schools with available funding data, correlations with achievement are confusing. The high-achieving schools we saw earlier in the Palo Alto area receive very high funding but, in Oakland, the schools with the highest funding have some of the lowest levels of achievement. South of Los Angeles, the high achieving schools in Huntington Beach are funded at levels close to and below $10,000 per student.\n\n\n\n\n\nOverall, regardless of area, higher per pupil funding is associated with lower growth scores. In California schools receive a base per-pupil grant dependent on the grades taught in the school. Schools receive supplemental funding based on the percent of students eligible for free and reduced lunch, the percent in the foster care system, and the percent that have limited English. We use a linear model of funding based solely on the percent of students eligible for free and reduced lunch to adjust funding. The negative relationship dissapears:\n\n\n\n\n\n\n\n\nIn the suburbs and city there appears to be a slight positive relationship between funding and achievement but our data and analysis really is not suited to pinpoint that effect.\nThere are various takeaways from this analysis. Socioeconomic status, measured as the percent of students eligible for free and reduced lunch, significantly effects achievement. Additional funding received by schools with a high proportion of disadvantaged students does not affect achievement enough to offset the impact of socioeconomic status. The Education Trust finds that California’s school funding scheme is relatively progressive when comparing high and low-poverty school districts (Morgan and Amerikaner 2018). When adjusting for the additional needs of low income students, however, they say that California is merely ‘neutral.’\n\n\n\n\n\n\n\n\nReferences\n\nBurnette, Daarel. 2019. “Student Outcomes: Does More Money Really Matter?” Education Week. https://www.edweek.org/policy-politics/student-outcomes-does-more-money-really-matter/2019/06.\n\n\nLips, Dan, Shanea Watkins, and John Fleming. 2008. “Does Spending More on Education Improve Academic Achievement?” Backgrounder. https://files.eric.ed.gov/fulltext/ED509499.pdf.\n\n\nMorgan, Ivy, and Ary Amerikaner. 2018. “Funding Gaps: An Analysis of School Funding Equity Across the u.s. And Within Each State.” The Education Trust. https://files.eric.ed.gov/fulltext/ED587198.pdf."
  },
  {
    "objectID": "motivation.html",
    "href": "motivation.html",
    "title": "Beyond the Report Card: Our Motivation",
    "section": "",
    "text": "A change in direction\nInitially, our focus was on the correlation between affordable housing and educational achievement. However, during the process of selecting appropriate educational proxies, we found ourselves delving into the factors behind the measurements of these proxies. As a result, we decided to seek the guidance of Professor Lesley Lavery, who specializes in public policies in education. We hope to gain a better understanding of the educational proxies currently in use and to investigate whether there are additional factors that impact educational outcomes and potentially render the current proxies interchangeable or distinct from other measures.\n\n\nPrevious literature\nThere are several reasons why education proxies differ, including the influence of socioeconomic status, the difficulty in standardizing scores across schools, and variations in school budgets. While % of high school graduates may be a more robust metric to estimate the education achievement level in different areas, it is harder to standardize score-related metrics due to differences in grading scales and the difficulty of obtaining student-level data (Lavery 2023).\nAdditionally, due to the diverse student body in the US, it is difficult to identify specific teaching approaches that are effective for particular groups of students. The Measures of Effective Teaching Project by the Gates Foundation aimed to establish innovative teacher-evaluation systems incorporating classroom observation rubrics and student achievement growth measures. Although the Gates Foundation allocated $600 million towards this initiative, it turned out to be a challenging task, particularly in identifying effective teaching elements that positively influence students’ academic performance. Consequently, this research heightened our curiosity in examining other factors that contribute to students’ achievements beyond teaching approaches (Will 2018).\nAnother discourse associated with academic achievement is how funding is allocated for education and whether spending more helps improve academic achievement. Funding disparities remain significant on a national level. Districts with the highest poverty rates in the country receive approximately $1,000 less per student in comparison to those with the lowest poverty rates. Furthermore, the variation is almost double, around $1,800 less per student, for districts serving the highest number of students of color versus those serving the lowest. However, there’s variation in state trend: While certain states allocate considerably more funding to their most impoverished districts, others provide notably less. Furthermore, when the researchers took into account that students living in poverty require extra support to excel academically, the funding differences between high and low poverty districts appear even more severe. This indicates that merely providing equal funding is insufficient (Morgan and Amerikaner 2018). This is a great insight that motivates us to look further into funding and the associated factors that can potentially confound funding in our analysis.\n\n\nWhy California?\nVarious socioeconomic factors can affect students’ academic performance, beyond just teaching methods. Given that California is a diverse state with people from different socioeconomic backgrounds, it presents an intriguing case study for our research topic, which focuses on exploring the socioeconomic factors that influence students’ grades.\n\n\n\n\n\nReferences\n\nLavery, Lesley. 2023. “Expert Interview.” Personal communication.\n\n\nMorgan, Ivy, and Ary Amerikaner. 2018. “Funding Gaps: An Analysis of School Funding Equity Across the u.s. And Within Each State.” The Education Trust. https://files.eric.ed.gov/fulltext/ED587198.pdf.\n\n\nWill, Madeline. 2018. “‘An Expensive Experiment’: Gates Teacher-Effectiveness Program Shows No Gains for Students.” EducationWeek. https://www.edweek.org/teaching-learning/an-expensive-experiment-gates-teacher-effectiveness-program-shows-no-gains-for-students/2018/06."
  },
  {
    "objectID": "model.html#why-lasso",
    "href": "model.html#why-lasso",
    "title": "Beyond the Report Card: What are the significant predictors?",
    "section": "Why LASSO",
    "text": "Why LASSO\nTo investigate the significance of predictors, we will utilize a technique known as LASSO (Least Absolute Shrinkage and Selection Operator). This approach involves identifying the most influential predictors out of numerous possibilities that explain the most variation in the outcome variable. In our case, the outcome variable is the specific educational outcome metric we are analyzing, while the predictors are various characteristics of the school."
  },
  {
    "objectID": "model.html#how-to-interpret-a-lasso-graph",
    "href": "model.html#how-to-interpret-a-lasso-graph",
    "title": "Beyond the Report Card: What are the significant predictors?",
    "section": "How to interpret a LASSO graph",
    "text": "How to interpret a LASSO graph\nLASSO provides us with a visual representation of which predictors are responsible for the most variation in the metric. It’s important to note a few things while analyzing the LASSO graphs below. Each line on the graph corresponds to an individual predictor, such as “percentage of students who are white” or “school grade span,” among others. The most significant predictors are indicated on the graph.\nA predictor is considered significant if its Y-value remains consistently above or below zero for high penalty values. In other words, if the line for a predictor on the graph reaches zero at higher X-values, it is more significant, meaning it accounts for a greater amount of variability in the outcome, compared to a predictor that reaches zero at low X-values."
  },
  {
    "objectID": "model.html#note-on-predictors",
    "href": "model.html#note-on-predictors",
    "title": "Beyond the Report Card: What are the significant predictors?",
    "section": "Note on predictors",
    "text": "Note on predictors\nSome predictors are numerical and some are categorical. Numerical predictors are fairly straightforward. If the line for a numerical predictor is above zero then the higher that predictor is for any given school, the higher the outcome metric will be. And vice versa if the predictor is below. Numerical predictors are predictors such as demographics. There are also categorical predictors. If a line for a categorical predictor (such as whether the school serves kids from K-12 or not) is above zero then if that category is true for a school the associated metric will be higher and vice versa if it is below."
  },
  {
    "objectID": "model.html#grade-cohort-standardized-gcs-scores",
    "href": "model.html#grade-cohort-standardized-gcs-scores",
    "title": "Beyond the Report Card: What are the significant predictors?",
    "section": "Grade Cohort Standardized (GCS) Scores",
    "text": "Grade Cohort Standardized (GCS) Scores\nFirst, we examine the significant predictors for the GCS Score at school level. This LASSO graph shows that the percentage of students who are Asian is a relatively strong positive predictor of GCS Score. However, the most significant predictors are the percentage of students receiving free/reduced lunch and the percentage of students considered economically disadvantaged (both with a negative correlation with the GCS Score)."
  },
  {
    "objectID": "model.html#ela-math-growth-scores",
    "href": "model.html#ela-math-growth-scores",
    "title": "Beyond the Report Card: What are the significant predictors?",
    "section": "ELA & Math Growth Scores",
    "text": "ELA & Math Growth Scores\nMoving on to the growth scores for ELA and Math, we observe that all the predictors converge to zero much faster than in the previous two graphs. This indicates that none of the predictors are as significant as those in the previous graphs. As well as converging to zero faster, the r-squared value (in the subtitle of the graphs) is much lower in the models for growth scores. This is further evidence that the predictors we have in our data account for less variability in the growth scores compared to the GCS score."
  },
  {
    "objectID": "result.html",
    "href": "result.html",
    "title": "Beyond the Report Card: Let’s discuss some results!",
    "section": "",
    "text": "What did we find, and what do they mean?\nThere is a high degree of variation in both the county and school-level achievement data. Wealthier counties and counties with large urban areas see higher average student achievement. When we separate economically disadvantaged and non-economically disadvantaged students the economically disadvantaged students have lower average achievement in both math and english. At the school level there is more significant variability. High-achieving and low-achieving schools can be found close to each other but there are many groups of high and low-achieving schools.\nDiving deeper into school funding, we find that schools with a higher proportion of disadvantaged students often have higher funding than schools with fewer disadvantaged students which may be misleading at first glance. When we account for the greater need of these economically disadvantaged students, disadvantaged schools appear to be underfunded. One of the explanations for this result is that it requires more funding to serve schools where poverty is concentrated. California is a relatively diverse state, and with a history of redlining, school segregation is inevitable. Therefore, underprivileged students tend to concentrate in certain areas. Although schools with a high proportion of economically disadvantaged students receive more funding, the majority of the funding goes to supporting students’ welfare, i.e. special education, free/reduced lunch programs, as well as human capital costs, i.e. teachers’ salaries and health services. Therefore, little is left to support students academically (Carrillo and Salhotra 2022; Will 2022; Lavery 2023). This shows that funding schools equally is not an equitable or effective solution to bridge the gap in socioeconomic status; there are still gaps in academic achievement left unbridged.\nFrom our LASSO graphs as well as the models we created we were able to compare the differences in GCS compared to growth scores. We saw that GCS was heavily correlated with factors out of control of a school such as the percentage of their students who are economically disadvantaged. This means that if we were to use this metric as a proxy for educational outcome, a lot of what we would be measuring would be inalienable factors about the students rather than how well the school is doing teaching their kids.\nFinally, after modeling our data with LASSO, it seems for the schools that we’re investigating, growth score did not have any predictors that were significantly able to account for the variation we saw across schools. In other words, if we were to use growth scores as a proxy for educational outcome we would not be measuring these inalienable factors that GCS measures. This is a good thing if what we want is a way to distinguish between schools that are doing the best they can and schools that could be doing better with the resources they have. Meaning that growth score is a relatively unbiased proxy to measure students’ achievement regardless of their socioeconomic status and the schools’ funding status.\n\n\nLimitations and moving forward\nThere are some limitations in our project. Firstly, we have excluded observations with incomplete data. Secondly, due to time constraints, we could only focus on employing LASSO for modeling purposes. Furthermore, we have to exclude a few datasets due to coverage problem, meaning that the data is only collected in certain counties north of CA and could potentially induce bias had we used them.\nMoving forward, there are some improvements that we would love to make in our project:\n\nWe recognize that there are differences in socioeconomic factors and educational measures among various states. Since we only focus on California, we would love to analyze data in other states in order to enhance the generalizability of our project.\nSince there might be spatial correlation in the data, we want to deal with missing data using spatial models instead of just dropping the observations.\nAs some of the datasets we obtained contain observations over multiple years, it would be beneficial to conduct time series analysis to explain trends and patterns over time.\nIn this analysis, since we gain various insights from our expert, Prof. Lesley Lavery, we would love to find and talk with more local experts, e.g. educators in California, for more context to dive deeper into our results.\nWe think it is interesting to explore other modeling techniques, i.e. hierarchical linear model as suggested by our expert, or adapt a nonlinearity assumption, to see how the results might vary.\nLast but not least, we hope to obtain more data that has better state coverage, i.e. data collected from across the state of interest rather than being limited to a small number of counties within the state.\n\n\n\n\n\n\nReferences\n\nCarrillo, Sequoia, and Pooja Salhotra. 2022. “The u.s. Student Population Is More Diverse, but Schools Are Still Highly Segregated.” NPR. https://www.npr.org/2022/07/14/1111060299/school-segregation-report.\n\n\nLavery, Lesley. 2023. “Expert Interview.” Personal communication.\n\n\nWill, Madeline. 2022. “Teacher Salaries Aren’t Keeping up with Inflation. See How Your State Compares.” EducationWeek. https://www.edweek.org/teaching-learning/teacher-salaries-arent-keeping-up-with-inflation-see-how-your-state-compares/2022/04."
  },
  {
    "objectID": "wideformatting.html",
    "href": "wideformatting.html",
    "title": "Untitled",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.2     ✔ purrr   1.0.1\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(readxl)\nlibrary(MetBrewer)\nlibrary(sf)\n\nLinking to GEOS 3.10.2, GDAL 3.4.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\nlibrary(rnaturalearth)"
  },
  {
    "objectID": "wideformatting.html#data-sources",
    "href": "wideformatting.html#data-sources",
    "title": "Untitled",
    "section": "Data Sources",
    "text": "Data Sources\n\nschool_data\nCodebook\n\nschool_data <- read.csv('AllDatasets/ca_education.csv') # dataset of public K-12 spending by school\n\nschool_data_clean <- school_data %>%\n  filter(flag_nerds == 'false') %>%\n  filter(flag_f33 != '1')\n\nschool_data identified by ncesid at school level – 10404\n\n\nela_metric_data\nCodebook\n\nela_metric_data <- read.csv('AllDatasets/ca_edu_metrics.csv') # 2022 Academic Indicator (English Language Arts/Literacy) Data File\n\nela_metric_data_clean <- ela_metric_data %>%\n  filter(cds > 0, rtype == 'S') %>% # school record\n  select(-color, -box) %>%\n  mutate(cds_standardized = as.character(paste0(\"0\", cds)))\n\ncolnames(ela_metric_data_clean) <- paste0(\"ela_data_\", colnames(ela_metric_data_clean))\nvaluecols<-names(ela_metric_data_clean)[10:21]\n\nela_wide <- ela_metric_data_clean %>% pivot_wider(names_from = ela_data_studentgroup, values_from = valuecols, names_sep = \"_\") %>% mutate(ela_data_cds = as.character(ela_data_cds))\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %>% select(valuecols)\n\n  # Now:\n  data %>% select(all_of(valuecols))\n\nSee <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\n\n\nela_metric_data identified by cds at school level – 9845 AND student group – 165532\n\n\nela and math metrics\n\nela_mth_proficiency_ranges<-read.csv(\"AllDatasets/nathanieldata.csv\") %>% filter(GRADE == \"00\" & CATEGORY == \"ALL\") %>% mutate(NCESSCH = as.character(NCESSCH), NCESSCH = paste0(\"0\",NCESSCH))\n\n\n\nscience_metric_data\nCodebook\n\nscience_metric_data <- read.csv('AllDatasets/science_ca_assesment.csv', sep = \"^\")\n\nscience_metrics_clean <- science_metric_data %>%\n  mutate(cds = as.character(paste0(0, paste0(paste0(County.Code,District.Code),paste0(0,School.Code))))) %>% # add cds identifier\n  # mutate(cds_standardized = ifelse(nchar(cds) == 13, as.character(paste0(0,cds)), cds)) %>% # there are school codes missing the last 0, this fixes that to match other cds\n  filter(County.Code > 0, Type.ID == 07) %>%\n  select(-County.Code, -District.Code, -School.Code, -Filler) \n\n\nvaluecols <- c(names(science_metrics_clean)[8:25],names(science_metrics_clean)[4:5])\nscience_metrics_wide <- science_metrics_clean %>% pivot_wider(names_from = Grade, values_from = valuecols)\ncolnames(science_metrics_wide) <- paste0(\"science_data_\", colnames(science_metrics_wide))\n\ncolnames(science_metrics_clean) <- paste0(\"science_data_\", colnames(science_metrics_clean))\n\nscience_metrics_clean identified by cds_standardized at school level – 8819 AND Grade – 25298\n\n\nstanford_data and cov\nCodebook\nCovariate Codebook\n\nstanford_data <- read.csv('AllDatasets/seda_school_pool_gcs_4.1.csv')\nstanford_cov <- read.csv(\"AllDatasets/seda_cov_school_pool_4.1.csv\")\n\nstanford_cov <- stanford_cov %>% filter(stateabb == \"CA\")\n\nstanford_data_clean <- stanford_data %>% \n  filter(stateabb == 'CA') %>% \n  select(sedasch, sedaschname, fips, stateabb, subcat, subgroup, gradecenter, gap, contains(\"avg\"), -ends_with(\"se\")) %>%\n  mutate(standardized_school_id = paste0(\"0\", sedasch)) %>% # adding 0 in front of school id to match the format of the school dataset\n  left_join(stanford_cov)\n\nJoining with `by = join_by(sedasch, fips, stateabb)`\n\n\nstanford_data AND stanford_cov identify eachother by sedasch\nstanford_data AND stanford_cov identified by standardized_school_id – 8512\n\n\nca_school_details\n\nca_school_details <- read_excel(\"AllDatasets/ca_school_details.xlsx\") # CA schools metadata\n\nca_school_details_clean <- ca_school_details %>%\n  filter(StatusType == \"Active\") %>%\n  filter(School != \"No Data\") %>%\n  mutate(school_id = paste0(NCESDist, NCESSchool))\n\nca_school_details_clean identified by school_id – 10629\n\n\ngrowth_aggr\n\ngrowth_aggr <- read_excel(\"AllDatasets/growthaggr.xlsx\")\n\ngrowth_aggr_clean <- growth_aggr %>% filter(rtype == \"S\") %>% \n  filter(studentgroup == \"ALL\") %>%\n  pivot_wider(names_from = subject, values_from = c(n_growthscores, growthscore, decilerank))"
  },
  {
    "objectID": "wideformatting.html#joining",
    "href": "wideformatting.html#joining",
    "title": "Untitled",
    "section": "Joining",
    "text": "Joining\n\nwide_merged_data <- ca_school_details_clean %>% \n  left_join(school_data_clean, by=c('school_id'='ncesid')) %>%\n  left_join(science_metrics_wide, by = c(\"CDSCode\"=\"science_data_cds\")) %>%\n  left_join(ela_wide, by = c(\"CDSCode\"=\"ela_data_cds_standardized\")) %>% \n  left_join(stanford_data_clean, by=c('school_id'='standardized_school_id')) %>% \n  mutate(ncesid = paste0(NCESDist,NCESSchool)) %>%\n  left_join(growth_aggr_clean, by = c('CDSCode' = 'cds')) %>%\n  left_join(ela_mth_proficiency_ranges, by=c(\"ncesid\"=\"NCESSCH\"))\n\n\n# save(wide_merged_data, file=\"WideMergedData.RData\")\n\n# names(wide_merged_data)\n\n\n# length(unique(wide_merged_data$CDSCode)) #10629 unique schools from the metadata\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$schoolname) == FALSE])) #4385 unique matched schools for Jeremy's california school data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$sedasch) == FALSE])) #7390 unique matched schools for Stanford data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$ela_data_cds) == FALSE])) #814 unique matched schools for ela data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$science_data_cds) == FALSE])) #495 unique matched schools for science data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$PE_data_cds) == FALSE])) #501 unique matched schools for pe data\n\n\n# wide_merged_data %>% filter(!is.na(urbanicity)) %>%\n#   ggplot(aes(x=as.numeric(pp_total_norm_NERDS), y=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)), color=urbanicity)) +\n#   geom_point(alpha = .1) + \n#   geom_smooth(method = lm) + \n#   facet_wrap(~urbanicity) + \n#   scale_x_continuous(limits = c(8000,18000)) + \n#   theme_nr()+\n#   labs(y=\"Grade Cohort Score\", x= \"Per Student Spending\") + guides(color=FALSE) +   geom_hline(yintercept = 0)\n\n\n# wide_merged_data %>% ggplot(aes(x=as.numeric(science_data_Percentage.Standard.Met.and.Above_13), y=(as.numeric(MTH_PCTPROF_max)))) +\n#   geom_point(alpha = .3) + \n#   geom_smooth(color=\"grey\",method=lm) + theme_nr() + labs(x = \"Percent Proficient on State Science Test\", y=\"Maximum* Percent Proficient on NAEP Math Test\", caption = \"*True value is hidden to protect student privacy at smaller schools\")\n# \n# wide_merged_data %>%\n#   ggplot(aes(x=as.numeric(perhsp), y=(as.numeric(perfrl)))) +\n#   geom_point(alpha = .05) + \n#   geom_smooth(color=\"black\") + theme_nr() + labs(x = \"Percent Hispanic\", y=\"Percent Eligible fro Free and Reduced Lunch\")\n# \n# \n# wide_merged_data %>% filter(!is.na(urbanicity)) %>%\n#   ggplot(aes(x=as.numeric(perfrl),y=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),color=State)) +\n#   geom_point(alpha = .05) +\n#   geom_smooth(method=lm)+\n#   guides(color=FALSE) + \n#   theme_nr()+\n#   labs(x=\"Percent Eligible for Free and Reduced Lunch\", y=\"Grade Cohort Score\")+\n#   geom_hline(yintercept = 0)\n# \n# wide_merged_data %>% filter(!is.na(urbanicity)) %>%\n#   ggplot(aes(x=as.numeric(perhsp),y=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),color=State)) +\n#   geom_point(alpha = .05) +\n#   geom_smooth()+\n#   guides(color=FALSE) + \n#   theme_nr()+\n#   labs(x=\"Percent Hispanic\", y=\"Grade Cohort Score\")+\n#   geom_hline(yintercept = 0)\n\n\n# counties <- st_as_sf(maps::map(\"county\", plot = FALSE, fill = TRUE))\n# counties <- subset(counties, grepl(\"california\", counties$ID))\n# world <- ne_countries(scale = \"medium\", returnclass = \"sf\")\n# \n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data = (wide_merged_data%>%filter(!is.na(gradecenter)&!is.na(gcs_mn_avg_ol))) , aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),size=as.numeric(ncesenroll)), alpha =.5) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 2) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Grade Cohort Score\",title = \"California School Location and Academic\\nPerformance\")+guides(size=FALSE)+theme(legend.position = c(.8,.8))\n# \n# # ----------------------------------------------------\n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data = (wide_merged_data%>%filter(!is.na(gradecenter)&!is.na(gcs_mn_avg_ol))) , aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),size=as.numeric(ncesenroll)), alpha =.5) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 7) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Grade Cohort Score\",title = \"Bay Area Academic Performance\")+guides(size=FALSE)+theme(legend.position = c(.28,.3)) +\n#   coord_sf(xlim=c(-121.25,-123.5), ylim= c(36.75,38.75))\n# \n# # -------------------------------------------------\n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data = (wide_merged_data%>%filter(!is.na(gradecenter)&!is.na(gcs_mn_avg_ol))) , aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),size=as.numeric(ncesenroll)), alpha =.5) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 2) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Grade Cohort Score\",title = \"Los Angeles and San Diego Academic\\nPerformance\")+guides(size=FALSE)+theme(legend.position = c(.3,.3)) +\n#   coord_sf(xlim=c(-117,-120), ylim= c(32,35))\n\n\n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data =((wide_merged_data %>% filter(!is.na(pp_total_norm_NERDS) & as.numeric(pp_total_norm_NERDS) > 7000 & as.numeric(pp_total_norm_NERDS) < 25000))), aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=as.numeric(pp_total_norm_NERDS),size=as.numeric(ncesenroll)), alpha =.25) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 2) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Per Student Spending\",title = \"California School Location and Per Student\\nSpending\")+guides(size=FALSE)+theme(legend.position = c(.8,.8))"
  },
  {
    "objectID": "county_insights.html",
    "href": "county_insights.html",
    "title": "Beyond the Report Card: What are the insights at the county level that we can observe?",
    "section": "",
    "text": "An overall look at Academic Achievement across Californian counties\nIn this analysis, we define academic achievement as the difference between the Grade Cohort Standardize (GCS) Scores and NAEP standard. As a reminder of the interpretation for GCS scores, we can look at this example again: If 4th-grade students at the school of interest have a GCS value of 5.03, these students’ scores indicate a level equivalent to 5th-grade, which is about one grade level higher than the national average (the reference group) in math.\nTo create this map, we calculated the difference in GCS scores from the grade levels for each grade-school cohort, then aggregated them by the Californian counties. We divided the score differences into 3 categories: 1-2 years behind, Less than 1 year behind, and Less than 1 year ahead.\n\n\n\n\n\n\n\n\n\n Looking at this map, it is clear that there is a significant difference in academic performance across various regions in California. The Bay Area and Orange County appear to outperform other counties, along with affluent tourist counties like Placer and El Dorado. However, for the remaining counties, while approximately half of them exhibit students with academic performance on par with the national average, a significant proportion of counties have students lagging behind by 1-2 years.\nWe recognize that there may be a huge wealth disparity among diverse communities in California. Therefore, our next step is to delve deeper into the social factors that may be contributing to what we’re observing on this map.\n\n\nFurther exploration into the county-level math and reasoning language arts (RLA) achievement of different student groups\nIndeed, according to Cano and Hong, California faces challenging income disparities and intricate demographics that extend beyond its public education system. Since 2008, California has implemented extensive reforms aimed at allocating more resources to high-needs students and addressing educational disparities, with some success. However, despite these efforts, Black, Latino, and low-income students continue to significantly underperform compared to Asian American, white, and wealthier students in both math and reading proficiency (Cano and Hong 2022). A UCLA research shows that Californian schools are the most segregated for Latinos, with 58% attending schools that are highly segregated. Additionally, The study also revealed that over 50% of Black students in California are concentrated in only 25 out of 1,000 school districts (Frankenberg et al. 2019).\nSince we’re interested in how different socioeconomic backgrounds might influence education achievement, we looked into how students classified as economically disadvantaged according to the Californian standard perform compared to those in the non-economically disadvantaged group in terms of GCS scores. By definition, students are typically considered economically disadvantaged if they come from a low-income household or meet other criteria for poverty, such as eligibility for free or reduced-price meals, homelessness, or foster care. The criteria for California can be found here. The GCS score differences are broken down into 6 categories, ranging from being 2+ years behind to 2+ years ahead compared to the NAEP standard. The GCS categories are also divided into two disciplines, i.e. math and RLA for both economically disadvantaged and non-economically disadvantaged groups.\n\n\n\n\n\n\n\n\n\n\n\n\n Although it is intuitive that economically disadvantaged students perform worse than their non-economically disadvantaged peers, it is still not at all less shocking when we looked at this map for the first time. The general trend shows that at county level, there is almost no overlapping in academic achievement between economically disadvantaged and non-economically disadvantaged student groups, for both math and RLA. Specifically, while the economically disadvantaged group is lagging behind by 1 to 2+ years behind the national standard, the more privileged group performs much better, having a performance gap of less than 1 year to being 2+ years ahead of the national standard.\n\n\n\n\n\nReferences\n\nCano, Ricardo, and Joe Hong. 2022. “Mind the Achievement Gap: California’s Disparities in Education, Explained.” Calmatters. https://calmatters.org/explainers/achievement-gap-california-explainer-schools-education-disparities-explained/.\n\n\nFrankenberg, Erica, Jongyeon Ee, Jennifer B. Ayscue, and Gary Orfield. 2019. “Harming Our Common Future: America’s Segregated Schools 65 Years aFter Brown.” The Civil Rights Project. www.civilrightsproject.ucla.edu."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement using California as a Case Study",
    "section": "",
    "text": "Hi everyone, we are Thu Dang, Nathaniel Reimer, and Jeremy Hubinger, and welcome to our Capstone Project for STAT 456: Projects in Data Science. As you can tell from the title, we are interested in exploring the factors that impacting academic achievement, using California as a case study. Before going into the details, we would love to express our gratitude to the people that have supervised our project and shared their valuable insights to help bring it to fruition. We would love to thank our education expert Prof. Lesley Lavery - we are so grateful for your insights in education policy and your expertise in giving us the much needed background for our findings. Thanks to you, we were able to explore this topic more thoroughly and interpret our results more thoughtfully. We would also love to thank our professor for this course, Prof. Brianna Heggeseth - we are so grateful for all of the support you have provided us and the amazing advanced data lessons throughout the course. We have used various skills you’ve taught us, and we’ve grown so much together in the journey of completing this project as a result.\nMeet the team…\n\n\n\nTeam picture. From left to right: Nathaniel Reimer, Thu Dang, Jeremy Hubinger\n\n\nYou can explore the diverse aspects of our project by navigating through various tabs on this website. Starting from our project’s inspiration, you can delve into the analysis of academic achievement insights at the county and school levels in California, learn about our model’s construction process, and discover some of the outcomes. Are you excited? Let’s get started!"
  },
  {
    "objectID": "IntermediateNarrative.html#analyses-with-a-short-description-of-results",
    "href": "IntermediateNarrative.html#analyses-with-a-short-description-of-results",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Analyses with a short description of results",
    "text": "Analyses with a short description of results\nThu’s results\nThis map shows the deviation in SEDA scores from the national standard for each county, providing a broad overview of academic achievement levels in Californian counties. Overall, areas in cities or richer suburbs (Silicon Valley, Los Angeles, San Diego) have higher academic performance than national average, shown through brigher colors (yellow and green). On the other hand, areas with fewer schools (e.g. Inyo – a national forest area) have lower academic performance than national average, denoted by darker (blue and purple) colors.\n\n\n\n\n\n\n\n\n\nJeremy’s results\nWe examined solely the schools for which we have complete data available, i.e., the schools in the intersection of our datasets. Among these schools, across all metrics, an increase in per-pupil government spending (both state and federal) showed a negative correlation with performance. At first glance, the outcomes appear to be linked to the increase in per-pupil spending when there is a significant percentage of students who are English learners, in the foster care system, or eligible for free/reduced lunch.\n\n\n\nNathaniel’s results\n\n\n\nSpending per student varies significantly across the state. We thought that this might explain some of the funding-achievement issue we had come across. After seeing that the same negative relationship existed to some degree in each locale we decided that location, or at least type of area, was not the factor we were looking for. It is also worth noting that the ‘Rural’ and ‘Town’ areas seem to be under performing for some reason.\n\n\n\n\n\n\n\n\n\nWe understand that funding for schools in California is based in part on the percent of students eligible for free and reduced lunch, the percent in the foster care system, and the percent that have limited English. So we decided to fit some simple models of funding and these variables. We then adjusted per student spending based on the simplest model: funding ~ free and reduced lunch. This flattened the relationship between funding and achievement and flipped the relationship between percent Hispanic and spending.\n\n\n\nThe flattened relationship persists in each area.\nThe percent of students eligible for free and reduced lunch directly influences spending in the state of California. However, in wealthy localities with strong property tax bases, funding often exceeds the amount allotted by the state of California. These areas also have a lower percent of students eligible for free and reduced lunch. So our model is not looking directly at the supplemental grant received for the percent of students eligible for free and reduced lunch. Nevertheless we think it provides a more accurate picture than the raw spending metric.\nThe adjustment is very very rudimentary and would benefit from more investigation. We could probably use school location in conjunction with census data to get some picture of property taxes and local funding, but variation in local tax and funding structures could make this difficult."
  },
  {
    "objectID": "IntermediateNarrative.html#project-plan",
    "href": "IntermediateNarrative.html#project-plan",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Project plan",
    "text": "Project plan\nMoving forward, we would love to:\n\nExpand further on funding metrics and explore ways to adjust them in a way that they don’t give a false picture when taken out of context (Nathaniel has put in some work in this regard and we have a plan to accomplish this)\nIdentify more potential metrics through bivariate visualizations and adjust them so that we can put all of them together into a model that explains different education proxies\nTell a better story with missing data (for example, why certain data is missing, where is it from, where does the data in our different datasets overlap and where does it not, are there trends here or not)"
  },
  {
    "objectID": "IntermediateNarrative.html#summary-of-contributions",
    "href": "IntermediateNarrative.html#summary-of-contributions",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Summary of contributions",
    "text": "Summary of contributions\nThu, Nathaniel, and Jeremy all contribute equally to this checkpoint. Specifically:\n\nThu was responsible for cleaning and standardizing school identifiers to merge all datasets together in long format. She also cleaned the data for and visualized the general map displaying the deviation in SEDA scores from the national standard for each county, which provides a broad overview of academic achievement levels in Californian counties. Lastly, she consolidated the narration for the results and also this write-up using all of Jeremy and Nathaniel’s inputs, and organized the slides for the intermediate presentation.\nNathaniel was responsible for cleaning and merging the dataset into a wide format, as well as creating several visualizations that aided us in developing a narrative about the funding for this intermediate visualization. Additionally, he proposed a new concept for modeling an adjusted funding metric, which will provide us with a more comprehensive understanding of the correlation between funding and academic achievement at the school level.\nJeremy was responsible for gathering and aggregating some of the initial datasets that Thu then later merged with other datasets. He also conducted various analyses to compare the trend of different educational proxies as school funding increases. Due to his extensive knowledge about California, he is the primary result interpreter of the team. This enables us to contextualize the outcomes and generate ideas for future steps. Furthermore, he played a role in exploring different potential variables by cleaning the data for and visualizing various bivariate graphs."
  },
  {
    "objectID": "data.html#a-comparison-of-different-performance-metrics",
    "href": "data.html#a-comparison-of-different-performance-metrics",
    "title": "Beyond the Report Card: Our Data",
    "section": "A comparison of different performance metrics",
    "text": "A comparison of different performance metrics\n\n\n\n\n\n\n\n\nOverall, GCS and growth scores seem to be pretty robust in the presence of funding compared to other metrics. Such robustness reinforces our choice of these two metrics as the primary indicators of academic accomplishment. You might notice that there’s a counter-intuitive trend between ELA, Science, and PE scores and funding, which we’ll explore and handle further in the subsequent analyses."
  }
]