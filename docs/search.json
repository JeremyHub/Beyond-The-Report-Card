[
  {
    "objectID": "school_insights.html#map-of-school-level-academic-achievement-categories-across-california-counties",
    "href": "school_insights.html#map-of-school-level-academic-achievement-categories-across-california-counties",
    "title": "Beyond the Report Card: What are the insights at the school level that we can observe?",
    "section": "Map of School-level academic achievement categories across California counties",
    "text": "Map of School-level academic achievement categories across California counties"
  },
  {
    "objectID": "school_insights.html#does-funding-impact-school-level-academic-achievement",
    "href": "school_insights.html#does-funding-impact-school-level-academic-achievement",
    "title": "Beyond the Report Card: What are the insights at the school level that we can observe?",
    "section": "Does funding impact school-level academic achievement?",
    "text": "Does funding impact school-level academic achievement?\n\n\n\n\n\nOverall, regardless of area, higher per pupil funding is associated with lower growth scores. In California schools receive a base per-pupil grant dependent on the grades taught in the school. Schools receive supplemental funding based on the percent of students eligible for free and reduced lunch, the percent in the foster care system, and the percent that have limited English. We use a linear model of funding based solely on the percent of students eligible for free and reduced lunch to adjust funding. The negative relationship dissapears:\n\n\n\n\n\n\n\n\nSocioeconomic status, measured as the percent of students eligible for free and reduced lunch, significantly effects achievement. Additional funding received by schools with a high proportion of disadvantaged students does not affect achievement enough to offset the impact of socioeconomic status."
  },
  {
    "objectID": "result.html",
    "href": "result.html",
    "title": "Beyond the Report Card: Let’s discuss some results!",
    "section": "",
    "text": "Add result here\n\nGrowth score is pretty robust since there are no variables that actually predict it."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement using California as a Case Study",
    "section": "",
    "text": "Hi everyone, we are Thu, Nathaniel, and Jeremy, and welcome to our Capstone Project for STAT 456: Projects in Data Science. As you can tell from the title, we are interested in exploring the factors that impacting academic achievement, using California as a case study. Meet the team…\n\nYou can explore the diverse aspects of our project by navigating through various tabs on this website. Starting from our project’s inspiration, you can delve into the analysis of academic achievement insights at the county and school levels in California, learn about our model’s construction process, and discover some of the outcomes. Are you excited? Let’s get started!"
  },
  {
    "objectID": "wideformatting.html",
    "href": "wideformatting.html",
    "title": "Untitled",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.2     ✔ purrr   1.0.1\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(readxl)\nlibrary(MetBrewer)\nlibrary(sf)\n\nLinking to GEOS 3.10.2, GDAL 3.4.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\nlibrary(rnaturalearth)"
  },
  {
    "objectID": "wideformatting.html#data-sources",
    "href": "wideformatting.html#data-sources",
    "title": "Untitled",
    "section": "Data Sources",
    "text": "Data Sources\n\nschool_data\nCodebook\n\nschool_data <- read.csv('AllDatasets/ca_education.csv') # dataset of public K-12 spending by school\n\nschool_data_clean <- school_data %>%\n  filter(flag_nerds == 'false') %>%\n  filter(flag_f33 != '1')\n\nschool_data identified by ncesid at school level – 10404\n\n\nela_metric_data\nCodebook\n\nela_metric_data <- read.csv('AllDatasets/ca_edu_metrics.csv') # 2022 Academic Indicator (English Language Arts/Literacy) Data File\n\nela_metric_data_clean <- ela_metric_data %>%\n  filter(cds > 0, rtype == 'S') %>% # school record\n  select(-color, -box) %>%\n  mutate(cds_standardized = as.character(paste0(\"0\", cds)))\n\ncolnames(ela_metric_data_clean) <- paste0(\"ela_data_\", colnames(ela_metric_data_clean))\nvaluecols<-names(ela_metric_data_clean)[10:21]\n\nela_wide <- ela_metric_data_clean %>% pivot_wider(names_from = ela_data_studentgroup, values_from = valuecols, names_sep = \"_\") %>% mutate(ela_data_cds = as.character(ela_data_cds))\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %>% select(valuecols)\n\n  # Now:\n  data %>% select(all_of(valuecols))\n\nSee <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\n\n\nela_metric_data identified by cds at school level – 9845 AND student group – 165532\n\n\nela and math metrics\n\nela_mth_proficiency_ranges<-read.csv(\"AllDatasets/nathanieldata.csv\") %>% filter(GRADE == \"00\" & CATEGORY == \"ALL\") %>% mutate(NCESSCH = as.character(NCESSCH), NCESSCH = paste0(\"0\",NCESSCH))\n\n\n\nscience_metric_data\nCodebook\n\nscience_metric_data <- read.csv('AllDatasets/science_ca_assesment.csv', sep = \"^\")\n\nscience_metrics_clean <- science_metric_data %>%\n  mutate(cds = as.character(paste0(0, paste0(paste0(County.Code,District.Code),paste0(0,School.Code))))) %>% # add cds identifier\n  # mutate(cds_standardized = ifelse(nchar(cds) == 13, as.character(paste0(0,cds)), cds)) %>% # there are school codes missing the last 0, this fixes that to match other cds\n  filter(County.Code > 0, Type.ID == 07) %>%\n  select(-County.Code, -District.Code, -School.Code, -Filler) \n\n\nvaluecols <- c(names(science_metrics_clean)[8:25],names(science_metrics_clean)[4:5])\nscience_metrics_wide <- science_metrics_clean %>% pivot_wider(names_from = Grade, values_from = valuecols)\ncolnames(science_metrics_wide) <- paste0(\"science_data_\", colnames(science_metrics_wide))\n\ncolnames(science_metrics_clean) <- paste0(\"science_data_\", colnames(science_metrics_clean))\n\nscience_metrics_clean identified by cds_standardized at school level – 8819 AND Grade – 25298\n\n\nstanford_data and cov\nCodebook\nCovariate Codebook\n\nstanford_data <- read.csv('AllDatasets/seda_school_pool_gcs_4.1.csv')\nstanford_cov <- read.csv(\"AllDatasets/seda_cov_school_pool_4.1.csv\")\n\nstanford_cov <- stanford_cov %>% filter(stateabb == \"CA\")\n\nstanford_data_clean <- stanford_data %>% \n  filter(stateabb == 'CA') %>% \n  select(sedasch, sedaschname, fips, stateabb, subcat, subgroup, gradecenter, gap, contains(\"avg\"), -ends_with(\"se\")) %>%\n  mutate(standardized_school_id = paste0(\"0\", sedasch)) %>% # adding 0 in front of school id to match the format of the school dataset\n  left_join(stanford_cov)\n\nJoining with `by = join_by(sedasch, fips, stateabb)`\n\n\nstanford_data AND stanford_cov identify eachother by sedasch\nstanford_data AND stanford_cov identified by standardized_school_id – 8512\n\n\nca_school_details\n\nca_school_details <- read_excel(\"AllDatasets/ca_school_details.xlsx\") # CA schools metadata\n\nca_school_details_clean <- ca_school_details %>%\n  filter(StatusType == \"Active\") %>%\n  filter(School != \"No Data\") %>%\n  mutate(school_id = paste0(NCESDist, NCESSchool))\n\nca_school_details_clean identified by school_id – 10629\n\n\ngrowth_aggr\n\ngrowth_aggr <- read_excel(\"AllDatasets/growthaggr.xlsx\")\n\ngrowth_aggr_clean <- growth_aggr %>% filter(rtype == \"S\") %>% \n  filter(studentgroup == \"ALL\") %>%\n  pivot_wider(names_from = subject, values_from = c(n_growthscores, growthscore, decilerank))"
  },
  {
    "objectID": "wideformatting.html#joining",
    "href": "wideformatting.html#joining",
    "title": "Untitled",
    "section": "Joining",
    "text": "Joining\n\nwide_merged_data <- ca_school_details_clean %>% \n  left_join(school_data_clean, by=c('school_id'='ncesid')) %>%\n  left_join(science_metrics_wide, by = c(\"CDSCode\"=\"science_data_cds\")) %>%\n  left_join(ela_wide, by = c(\"CDSCode\"=\"ela_data_cds_standardized\")) %>% \n  left_join(stanford_data_clean, by=c('school_id'='standardized_school_id')) %>% \n  mutate(ncesid = paste0(NCESDist,NCESSchool)) %>%\n  left_join(growth_aggr_clean, by = c('CDSCode' = 'cds')) %>%\n  left_join(ela_mth_proficiency_ranges, by=c(\"ncesid\"=\"NCESSCH\"))\n\n\n# save(wide_merged_data, file=\"WideMergedData.RData\")\n\n# names(wide_merged_data)\n\n\n# length(unique(wide_merged_data$CDSCode)) #10629 unique schools from the metadata\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$schoolname) == FALSE])) #4385 unique matched schools for Jeremy's california school data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$sedasch) == FALSE])) #7390 unique matched schools for Stanford data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$ela_data_cds) == FALSE])) #814 unique matched schools for ela data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$science_data_cds) == FALSE])) #495 unique matched schools for science data\n# length(unique(wide_merged_data$CDSCode[is.na(wide_merged_data$PE_data_cds) == FALSE])) #501 unique matched schools for pe data\n\n\n# wide_merged_data %>% filter(!is.na(urbanicity)) %>%\n#   ggplot(aes(x=as.numeric(pp_total_norm_NERDS), y=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)), color=urbanicity)) +\n#   geom_point(alpha = .1) + \n#   geom_smooth(method = lm) + \n#   facet_wrap(~urbanicity) + \n#   scale_x_continuous(limits = c(8000,18000)) + \n#   theme_nr()+\n#   labs(y=\"Grade Cohort Score\", x= \"Per Student Spending\") + guides(color=FALSE) +   geom_hline(yintercept = 0)\n\n\n# wide_merged_data %>% ggplot(aes(x=as.numeric(science_data_Percentage.Standard.Met.and.Above_13), y=(as.numeric(MTH_PCTPROF_max)))) +\n#   geom_point(alpha = .3) + \n#   geom_smooth(color=\"grey\",method=lm) + theme_nr() + labs(x = \"Percent Proficient on State Science Test\", y=\"Maximum* Percent Proficient on NAEP Math Test\", caption = \"*True value is hidden to protect student privacy at smaller schools\")\n# \n# wide_merged_data %>%\n#   ggplot(aes(x=as.numeric(perhsp), y=(as.numeric(perfrl)))) +\n#   geom_point(alpha = .05) + \n#   geom_smooth(color=\"black\") + theme_nr() + labs(x = \"Percent Hispanic\", y=\"Percent Eligible fro Free and Reduced Lunch\")\n# \n# \n# wide_merged_data %>% filter(!is.na(urbanicity)) %>%\n#   ggplot(aes(x=as.numeric(perfrl),y=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),color=State)) +\n#   geom_point(alpha = .05) +\n#   geom_smooth(method=lm)+\n#   guides(color=FALSE) + \n#   theme_nr()+\n#   labs(x=\"Percent Eligible for Free and Reduced Lunch\", y=\"Grade Cohort Score\")+\n#   geom_hline(yintercept = 0)\n# \n# wide_merged_data %>% filter(!is.na(urbanicity)) %>%\n#   ggplot(aes(x=as.numeric(perhsp),y=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),color=State)) +\n#   geom_point(alpha = .05) +\n#   geom_smooth()+\n#   guides(color=FALSE) + \n#   theme_nr()+\n#   labs(x=\"Percent Hispanic\", y=\"Grade Cohort Score\")+\n#   geom_hline(yintercept = 0)\n\n\n# counties <- st_as_sf(maps::map(\"county\", plot = FALSE, fill = TRUE))\n# counties <- subset(counties, grepl(\"california\", counties$ID))\n# world <- ne_countries(scale = \"medium\", returnclass = \"sf\")\n# \n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data = (wide_merged_data%>%filter(!is.na(gradecenter)&!is.na(gcs_mn_avg_ol))) , aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),size=as.numeric(ncesenroll)), alpha =.5) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 2) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Grade Cohort Score\",title = \"California School Location and Academic\\nPerformance\")+guides(size=FALSE)+theme(legend.position = c(.8,.8))\n# \n# # ----------------------------------------------------\n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data = (wide_merged_data%>%filter(!is.na(gradecenter)&!is.na(gcs_mn_avg_ol))) , aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),size=as.numeric(ncesenroll)), alpha =.5) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 7) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Grade Cohort Score\",title = \"Bay Area Academic Performance\")+guides(size=FALSE)+theme(legend.position = c(.28,.3)) +\n#   coord_sf(xlim=c(-121.25,-123.5), ylim= c(36.75,38.75))\n# \n# # -------------------------------------------------\n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data = (wide_merged_data%>%filter(!is.na(gradecenter)&!is.na(gcs_mn_avg_ol))) , aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=(as.numeric(gcs_mn_avg_ol)-as.numeric(gradecenter)),size=as.numeric(ncesenroll)), alpha =.5) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 2) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Grade Cohort Score\",title = \"Los Angeles and San Diego Academic\\nPerformance\")+guides(size=FALSE)+theme(legend.position = c(.3,.3)) +\n#   coord_sf(xlim=c(-117,-120), ylim= c(32,35))\n\n\n# ggplot(data = world) +\n#   geom_sf(data = counties, fill='#f0f1f9') + \n#   geom_point(data =((wide_merged_data %>% filter(!is.na(pp_total_norm_NERDS) & as.numeric(pp_total_norm_NERDS) > 7000 & as.numeric(pp_total_norm_NERDS) < 25000))), aes(x=as.numeric(Longitude),y=as.numeric(Latitude),color=as.numeric(pp_total_norm_NERDS),size=as.numeric(ncesenroll)), alpha =.25) +\n#   theme_classic() +\n#   scale_color_met_c(\"Benedictus\",direction = 1) +\n#   scale_size_area(max_size = 2) + theme_nr() +\n#   labs(x=\"Longitude\",y=\"Latitude\",color=\"Per Student Spending\",title = \"California School Location and Per Student\\nSpending\")+guides(size=FALSE)+theme(legend.position = c(.8,.8))"
  },
  {
    "objectID": "IntermediateNarrative.html#analyses-with-a-short-description-of-results",
    "href": "IntermediateNarrative.html#analyses-with-a-short-description-of-results",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Analyses with a short description of results",
    "text": "Analyses with a short description of results\nThu’s results\nThis map shows the deviation in SEDA scores from the national standard for each county, providing a broad overview of academic achievement levels in Californian counties. Overall, areas in cities or richer suburbs (Silicon Valley, Los Angeles, San Diego) have higher academic performance than national average, shown through brigher colors (yellow and green). On the other hand, areas with fewer schools (e.g. Inyo – a national forest area) have lower academic performance than national average, denoted by darker (blue and purple) colors.\n\n\n\n\n\n\n\n\n\n\n\nJeremy’s results\nWe examined solely the schools for which we have complete data available, i.e., the schools in the intersection of our datasets. Among these schools, across all metrics, an increase in per-pupil government spending (both state and federal) showed a negative correlation with performance. At first glance, the outcomes appear to be linked to the increase in per-pupil spending when there is a significant percentage of students who are English learners, in the foster care system, or eligible for free/reduced lunch.\n\n\n\n\n\nNathaniel’s results\n\n\n\n\n\nSpending per student varies significantly across the state. We thought that this might explain some of the funding-achievement issue we had come across. After seeing that the same negative relationship existed to some degree in each locale we decided that location, or at least type of area, was not the factor we were looking for. It is also worth noting that the ‘Rural’ and ‘Town’ areas seem to be under performing for some reason.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe understand that funding for schools in California is based in part on the percent of students eligible for free and reduced lunch, the percent in the foster care system, and the percent that have limited English. So we decided to fit some simple models of funding and these variables. We then adjusted per student spending based on the simplest model: funding ~ free and reduced lunch. This flattened the relationship between funding and achievement and flipped the relationship between percent Hispanic and spending.\n\n\n\n\n\nThe flattened relationship persists in each area.\nThe percent of students eligible for free and reduced lunch directly influences spending in the state of California. However, in wealthy localities with strong property tax bases, funding often exceeds the amount allotted by the state of California. These areas also have a lower percent of students eligible for free and reduced lunch. So our model is not looking directly at the supplemental grant received for the percent of students eligible for free and reduced lunch. Nevertheless we think it provides a more accurate picture than the raw spending metric.\nThe adjustment is very very rudimentary and would benefit from more investigation. We could probably use school location in conjunction with census data to get some picture of property taxes and local funding, but variation in local tax and funding structures could make this difficult."
  },
  {
    "objectID": "IntermediateNarrative.html#project-plan",
    "href": "IntermediateNarrative.html#project-plan",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Project plan",
    "text": "Project plan\nMoving forward, we would love to:\n\nExpand further on funding metrics and explore ways to adjust them in a way that they don’t give a false picture when taken out of context (Nathaniel has put in some work in this regard and we have a plan to accomplish this)\nIdentify more potential metrics through bivariate visualizations and adjust them so that we can put all of them together into a model that explains different education proxies\nTell a better story with missing data (for example, why certain data is missing, where is it from, where does the data in our different datasets overlap and where does it not, are there trends here or not)"
  },
  {
    "objectID": "IntermediateNarrative.html#summary-of-contributions",
    "href": "IntermediateNarrative.html#summary-of-contributions",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Summary of contributions",
    "text": "Summary of contributions\nThu, Nathaniel, and Jeremy all contribute equally to this checkpoint. Specifically:\n\nThu was responsible for cleaning and standardizing school identifiers to merge all datasets together in long format. She also cleaned the data for and visualized the general map displaying the deviation in SEDA scores from the national standard for each county, which provides a broad overview of academic achievement levels in Californian counties. Lastly, she consolidated the narration for the results and also this write-up using all of Jeremy and Nathaniel’s inputs, and organized the slides for the intermediate presentation.\nNathaniel was responsible for cleaning and merging the dataset into a wide format, as well as creating several visualizations that aided us in developing a narrative about the funding for this intermediate visualization. Additionally, he proposed a new concept for modeling an adjusted funding metric, which will provide us with a more comprehensive understanding of the correlation between funding and academic achievement at the school level.\nJeremy was responsible for gathering and aggregating some of the initial datasets that Thu then later merged with other datasets. He also conducted various analyses to compare the trend of different educational proxies as school funding increases. Due to his extensive knowledge about California, he is the primary result interpreter of the team. This enables us to contextualize the outcomes and generate ideas for future steps. Furthermore, he played a role in exploring different potential variables by cleaning the data for and visualizing various bivariate graphs."
  },
  {
    "objectID": "thing.html#comparing-performance-metrics",
    "href": "thing.html#comparing-performance-metrics",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Comparing Performance Metrics",
    "text": "Comparing Performance Metrics"
  },
  {
    "objectID": "thing.html#at-the-county-level",
    "href": "thing.html#at-the-county-level",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "At The County Level",
    "text": "At The County Level"
  },
  {
    "objectID": "thing.html#at-the-school-level",
    "href": "thing.html#at-the-school-level",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "At The School Level",
    "text": "At The School Level"
  },
  {
    "objectID": "thing.html#funding-and-achievement-correlation",
    "href": "thing.html#funding-and-achievement-correlation",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Funding and Achievement Correlation",
    "text": "Funding and Achievement Correlation\n\n\n\n\n\n                    Estimate Std. Error  t value     Pr(>|t|)\n(Intercept)        11365.441   184.1742 61.71027 0.000000e+00\nas.numeric(perfrl)  3170.302   283.2011 11.19452 1.334886e-28"
  },
  {
    "objectID": "thing.html#something-something-gcs-map",
    "href": "thing.html#something-something-gcs-map",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Something Something GCS Map",
    "text": "Something Something GCS Map"
  },
  {
    "objectID": "thing.html#choosing-variables",
    "href": "thing.html#choosing-variables",
    "title": "Beyond the Report Card: Investigating the Factors that Define Educational Achievement",
    "section": "Choosing Variables",
    "text": "Choosing Variables"
  },
  {
    "objectID": "county_insights.html#aggregated-county-level-math-and-reasoning-language-arts-rla-achievement-of-students-of-different-socioeconomic-status-groups",
    "href": "county_insights.html#aggregated-county-level-math-and-reasoning-language-arts-rla-achievement-of-students-of-different-socioeconomic-status-groups",
    "title": "Beyond the Report Card: What are the insights at the county level that we can observe?",
    "section": "Aggregated county-level math and reasoning language arts (RLA) achievement of students of different socioeconomic status groups",
    "text": "Aggregated county-level math and reasoning language arts (RLA) achievement of students of different socioeconomic status groups"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Beyond the Report Card: Our Motivation",
    "section": "",
    "text": "A sneak peek into the data\nThe data set we have includes a range of school-related variables such as location details, funding, and aggregated scores in various subjects. Specifically, the score variables cover the general grade-cohort-standardized achievement score, as well as scores in reading, science, and physical education.\nWe aggregate our dataset from 5 different datasets. We use data from The California Department of Education, Georgetown University, and the Educational Opportunity Project at Stanford University.\nScience Testing Data Codebook\nOur science test data is from the California Department of Education, specifically, from the 2021-2022 school year. It is from the California Science Test, in which there are three different categories, namely Life sciences, Physical sciences, and Earth and Space sciences.\nEnglish Testing Data Codebook\nThe data we have for English Language Arts / Literature is also from the California Department of Education, specifically from 2022. It tells us for each student group within each school their level of proficiency.\nPhysical Education Data Codebook\nOur PE data comes from the California Department Education from the 2018-2019 school year. It has 7 different types of exercises and each school’s grade’s proficiency on each type of exercise.\nSchool Funding Data Codebook\nOur school funding data is aggregated 2019-2020 data from different federal and state sources. It is compiled into the dataset we are using by Georgetown University researchers. It has information about funding going to a school from the state, local, and federal governments, as well as metadata about the school such as enrollment, as well as data about the income levels of the students at the school.\nThe Educational Opportunity Project at Stanford University (SEDA) Codebook Covariate Codebook\nThe SEDA dataset contains school-level standardized academic achievement data across all Californian schools. These achievement scores are graded and cohort standardized against the NAEP standard, indicating whether the students in a particular school and grade level are meeting the national standard for their grade. For instance, if a school’s 4th-grade students score 3.5, it indicates that they are lagging behind the national standard by 0.5 points. The achievement estimates are calculated using Ordinary Least Square (OLS) and Empirical Bayesian (EB) techniques.\nSchool Details Codebook\nThis contains metadata on 10629 California Schools, including both the nationally used school identifier, or NCES ID, and the California CDS code. We use this to join our data from our different sources. This dataset also contains the longitude and latitude of the schools which has been very useful for EDA so far.\nAggregated Growth Codebook\nThis contains data on Mathematics and English Language Arts growth by school and student group for California Schools. California developed the growth model to show how much student’s scores were growing from year to year.\n\n\nGoing into details regarding the metrics considered in this analysis\nIn this analysis, we focused on using Grade Cohort Standardized scores, which is a metric created by the SEDA project, and growth score (?), both at county- and school-level. Additionally, we also considered school-level test scores in various subjects, including English, Science, and Physical Education (PE).\nGrade Cohort Standardized (GCS) scores: According to the Stanford Codebook, “[t]he GCS scale standardizes the unit means relative to the average difference in NAEP scores between students one grade level apart” (“Methods: How SEDA Produced Estimates of Student Performance That Are Comparable Across Places, Grades, and Years.” 2022). NAEP stands for National Assessment of Educational Progress, which is an assessment program in the United States that aiming to assess and measure the academic performance of students across different subjects and grades, generally referred to as the Nation’s Report Card (“About NAEP” 2023). The GCS scale allows users to understand one unit as being equivalent to one grade level. In Grade 3, the national average performance is 3 units, while in Grade 4, it is 4 units, and so on. Here are two brief examples to interpreting GCS values: If 4th-grade students at the school of interest have a GCS value of 5.03, these students’ scores indicate a level equivalent to 5th-grade, which is about one grade level higher than the national average (the reference group) in math. Vice versa, if 3rd-grade students at the school of interest have a GCS value of 2.39, these students’ reading scores indicate a level about half a grade level lower than the national average for 3rd-grade students (“Methods: How SEDA Produced Estimates of Student Performance That Are Comparable Across Places, Grades, and Years.” 2022). GCS values are aggregated over the years of 2009, 2011, 2013, and 2015, and and are collected at school- and county-level.\nGrowth score: Aggregate growth scores are available for English and Mathematics broken down by school and student group. They measure how close the students growth is to their expected growth. A growth score of 100 indicates students are meeting expected growth; below 100 indicates growth below expectations; and above 100 indicates growth above expectations. Since the scores measure growth they are based on multiple years of testing data: the 2016-17, 2017-18, and 2018-19 school years. Pandemic disruption means that the current growth scores are not actionable. Growth scores will be released again in 2024. Nevertheless, the scores are still useful for our analysis.\nSubject-specific test scores: We obtained data on test scores for various subjects, including English, Science, and PE. During our initial investigation, after joining these test score datasets with the SEDA and funding data, we saw that the test scores only matched up with a very small percentage of schools in our dataset. Further investigation shows that the test scores are only collected in the East Bay area and various northern CA counties. Since it is desirable to have a full coverage of state scores for the subsequent analysis and modeling process, we decided not to use the subject-specific test score datasets.\nWe can add that interesting viz here – what interesting viz?\n\n\n\n\n\nReferences\n\n“About NAEP.” 2023. National Assessment Governing Board. https://www.nagb.gov/naep/about-naep.html.\n\n\n“Methods: How SEDA Produced Estimates of Student Performance That Are Comparable Across Places, Grades, and Years.” 2022. The Educational Opportunity Project at Stanford University. https://edopportunity.org/methods/."
  },
  {
    "objectID": "motivation.html",
    "href": "motivation.html",
    "title": "Beyond the Report Card: Our Motivation",
    "section": "",
    "text": "A change in direction\nInitially, our focus was on the correlation between affordable housing and educational achievement. However, during the process of selecting appropriate educational proxies, we found ourselves delving into the factors behind the measurements of these proxies. As a result, we decided to seek the guidance of Professor Lesley Lavery, who specializes in public policies in education. We hope to gain a better understanding of the educational proxies currently in use and to investigate whether there are additional factors that impact educational outcomes and potentially render the current proxies interchangeable or distinct from other measures.\n\n\nPrevious literature\nThere are several reasons why education proxies differ, including the influence of socioeconomic status, the difficulty in standardizing scores across schools, and variations in school budgets. While % of high school graduates may be a more robust metric to estimate the education achievement level in different areas, it is harder to standardize score-related metrics due to differences in grading scales and the difficulty of obtaining student-level data (“Expert Interview with Lesley Lavery at Macalester College on 8 March 2023” 2023).\nAdditionally, due to the diverse student body in the US, it is difficult to identify specific teaching approaches that are effective for particular groups of students. The Measures of Effective Teaching Project by the Gates Foundation aimed to establish innovative teacher-evaluation systems incorporating classroom observation rubrics and student achievement growth measures. Although the Gates Foundation allocated $600 million towards this initiative, it turned out to be a challenging task, particularly in identifying effective teaching elements that positively influence students’ academic performance. Consequently, this research heightened our curiosity in examining other factors that contribute to students’ achievements beyond teaching approaches (Will 2018).\nAnother discourse associated with academic achievement is funding allocation and whether spending more helps improve academic achievement. (to be added more)\n\n\nWhy California?\nVarious socioeconomic factors can affect students’ academic performance, beyond just teaching methods. Given that California is a diverse state with people from different socioeconomic backgrounds, it presents an intriguing case study for our research topic, which focuses on exploring the socioeconomic factors that influence students’ grades.\n\n\n\n\n\nReferences\n\n“Expert Interview with Lesley Lavery at Macalester College on 8 March 2023.” 2023.\n\n\nWill, Madeline. 2018. “‘An Expensive Experiment’: Gates Teacher-Effectiveness Program Shows No Gains for Students.” EducationWeek. https://www.edweek.org/teaching-learning/an-expensive-experiment-gates-teacher-effectiveness-program-shows-no-gains-for-students/2018/06."
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "Beyond the Report Card: What are the significant predictors?",
    "section": "",
    "text": "LASSO code"
  },
  {
    "objectID": "county_insights.html#further-exploration-into-the-county-level-math-and-reasoning-language-arts-rla-achievement-of-economically-disadvantaged-and-non-economically-disadvantaged-student-groups",
    "href": "county_insights.html#further-exploration-into-the-county-level-math-and-reasoning-language-arts-rla-achievement-of-economically-disadvantaged-and-non-economically-disadvantaged-student-groups",
    "title": "Beyond the Report Card: What are the insights at the county level that we can observe?",
    "section": "Further exploration into the county-level math and reasoning language arts (RLA) achievement of economically disadvantaged and non-economically disadvantaged student groups",
    "text": "Further exploration into the county-level math and reasoning language arts (RLA) achievement of economically disadvantaged and non-economically disadvantaged student groups\nIndeed, according to Cano and Hong, California faces challenging income disparities and intricate demographics that extend beyond its public education system. Since 2008, California has implemented extensive reforms aimed at allocating more resources to high-needs students and addressing educational disparities, with some success. However, despite these efforts, Black, Latino, and low-income students continue to significantly underperform compared to Asian American, white, and wealthier students in both math and reading proficiency [@cal_matter]. A UCLA research shows that Californian schools are the most segregated for Latinos, with 58% attending schools that are highly segregated. Additionally, The study also revealed that over 50% of Black students in California are concentrated in only 25 out of 1,000 school districts [@ucla_article].\nSince we’re interested in how different socioeconomic backgrounds might influence education achievement, we looked into how students classified as economically disadvantaged according to the Californian standard perform compared to those in the non-economically disadvantaged group in terms of GCS scores. By definition, students are typically considered economically disadvantaged if they come from a low-income household or meet other criteria for poverty, such as eligibility for free or reduced-price meals, homelessness, or foster care. The criteria for California can be checked out here."
  },
  {
    "objectID": "county_insights.html#further-exploration-into-the-county-level-math-and-reasoning-language-arts-rla-achievement-of-different-student-groups",
    "href": "county_insights.html#further-exploration-into-the-county-level-math-and-reasoning-language-arts-rla-achievement-of-different-student-groups",
    "title": "Beyond the Report Card: What are the insights at the county level that we can observe?",
    "section": "Further exploration into the county-level math and reasoning language arts (RLA) achievement of different student groups",
    "text": "Further exploration into the county-level math and reasoning language arts (RLA) achievement of different student groups\nIndeed, according to Cano and Hong, California faces challenging income disparities and intricate demographics that extend beyond its public education system. Since 2008, California has implemented extensive reforms aimed at allocating more resources to high-needs students and addressing educational disparities, with some success. However, despite these efforts, Black, Latino, and low-income students continue to significantly underperform compared to Asian American, white, and wealthier students in both math and reading proficiency [@cal_matter]. A UCLA research shows that Californian schools are the most segregated for Latinos, with 58% attending schools that are highly segregated. Additionally, The study also revealed that over 50% of Black students in California are concentrated in only 25 out of 1,000 school districts [@ucla_article].\nSince we’re interested in how different socioeconomic backgrounds might influence education achievement, we looked into how students classified as economically disadvantaged according to the Californian standard perform compared to those in the non-economically disadvantaged group in terms of GCS scores. By definition, students are typically considered economically disadvantaged if they come from a low-income household or meet other criteria for poverty, such as eligibility for free or reduced-price meals, homelessness, or foster care. The criteria for California can be found here. The GCS score differences are broken down into 6 categories, ranging from being 2+ years behind to 2+ years ahead compared to the NAEP standard. The GCS categories are also divided into two disciplines, i.e. math and RLA for both economically disadvantaged and non-economically disadvantaged groups.\n\n\n\n\n\n\n\n\n\n\n\n\nAlthough it is intuitive that economically disadvantaged students perform worse than their non-economically disadvantaged peers, it is still not at all less shocking when we looked at this map for the first time. The general trend shows that at county level, there is almost no overlapping in academic achievement between economically disadvantaged and non-economically disadvantaged student groups, for both math and RLA. Specifically, while the economically disadvantaged group is lagging behind by 1 to 2+ years behind the national standard, the more privileged group performs much better, having a performance gap of less than 1 year to being 2+ years ahead of the national standard."
  },
  {
    "objectID": "county_insights.html",
    "href": "county_insights.html",
    "title": "Beyond the Report Card: What are the insights at the county level that we can observe?",
    "section": "",
    "text": "An overall look at Academic Achievement across Californian counties\nIn this analysis, we define academic achievement as the difference between the Grade Cohort Standardize (GCS) Scores and NAEP standard. As a reminder of the interpretation for GCS scores, we can look at this example again: If 4th-grade students at the school of interest have a GCS value of 5.03, these students’ scores indicate a level equivalent to 5th-grade, which is about one grade level higher than the national average (the reference group) in math.\nTo create this map, we calculated the difference in GCS scores from the grade levels for each grade-school cohort, then aggregated them by the Californian counties. We divided the score differences into 3 categories: 1-2 years behind, Less than 1 year behind, and Less than 1 year ahead.\n\n\n\n\n\n\n\n\n\n Looking at this map, it is clear that there is a significant difference in academic performance across various regions in California. The Bay Area and Orange County appear to outperform other counties, along with affluent tourist counties like Placer and El Dorado. However, for the remaining counties, while approximately half of them exhibit students with academic performance on par with the national average, a significant proportion of counties have students lagging behind by 1-2 years.\nWe recognize that there may be a huge wealth disparity among diverse communities in California. Therefore, our next step is to delve deeper into the social factors that may be contributing to what we’re observing on this map.\n\n\nFurther exploration into the county-level math and reasoning language arts (RLA) achievement of different student groups\nIndeed, according to Cano and Hong, California faces challenging income disparities and intricate demographics that extend beyond its public education system. Since 2008, California has implemented extensive reforms aimed at allocating more resources to high-needs students and addressing educational disparities, with some success. However, despite these efforts, Black, Latino, and low-income students continue to significantly underperform compared to Asian American, white, and wealthier students in both math and reading proficiency (Ricardo Cano 2022). A UCLA research shows that Californian schools are the most segregated for Latinos, with 58% attending schools that are highly segregated. Additionally, The study also revealed that over 50% of Black students in California are concentrated in only 25 out of 1,000 school districts (Erica Frankenberg 2019).\nSince we’re interested in how different socioeconomic backgrounds might influence education achievement, we looked into how students classified as economically disadvantaged according to the Californian standard perform compared to those in the non-economically disadvantaged group in terms of GCS scores. By definition, students are typically considered economically disadvantaged if they come from a low-income household or meet other criteria for poverty, such as eligibility for free or reduced-price meals, homelessness, or foster care. The criteria for California can be found here. The GCS score differences are broken down into 6 categories, ranging from being 2+ years behind to 2+ years ahead compared to the NAEP standard. The GCS categories are also divided into two disciplines, i.e. math and RLA for both economically disadvantaged and non-economically disadvantaged groups.\n\n\n\n\n\n\n\n\n\n\n\n\n Although it is intuitive that economically disadvantaged students perform worse than their non-economically disadvantaged peers, it is still not at all less shocking when we looked at this map for the first time. The general trend shows that at county level, there is almost no overlapping in academic achievement between economically disadvantaged and non-economically disadvantaged student groups, for both math and RLA. Specifically, while the economically disadvantaged group is lagging behind by 1 to 2+ years behind the national standard, the more privileged group performs much better, having a performance gap of less than 1 year to being 2+ years ahead of the national standard.\n\n\n\n\n\nReferences\n\nErica Frankenberg, Jennifer B. Ayscue, Jongyeon Ee. 2019. “Harming Our Common Future: America’s Segregated Schools 65 Years aFter Brown.” The Civil Rights Project. www.civilrightsproject.ucla.edu.\n\n\nRicardo Cano, Joe Hong. 2022. “Mind the Achievement Gap: California’s Disparities in Education, Explained.” Calmatters. https://calmatters.org/explainers/achievement-gap-california-explainer-schools-education-disparities-explained/."
  }
]